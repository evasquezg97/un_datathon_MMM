{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luism\\miniconda3\\envs\\undatathon\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data with descriptions\n",
    "df = pd.read_csv('data\\geocoded_addresses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(\n",
    "    input_csv: Union[str, pd.DataFrame],\n",
    "    output_csv: str,\n",
    "    embedding_model_name: str = \"all-MiniLM-L6-v2\",\n",
    "    ) -> None:\n",
    "    \"\"\"\n",
    "    Generates combined text and geospatial embeddings for places.\n",
    "\n",
    "    Parameters:\n",
    "    - input_csv (str): Path to the input CSV file with place data.\n",
    "    - output_csv (str): Path to save the output CSV with embeddings.\n",
    "    - embedding_model_name (str): Pretrained SentenceTransformer model name.\n",
    "    - pca_components (int): Number of PCA components for dimensionality reduction.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(input_csv, str):\n",
    "        df = pd.read_csv(input_csv)\n",
    "    elif isinstance(input_csv, pd.DataFrame):\n",
    "        df = input_csv\n",
    "    else:\n",
    "        raise ValueError(\"input_csv should be a path to a CSV file or a DataFrame\")\n",
    "\n",
    "    # check if there is description and used columns\n",
    "    if \"description\" not in df.columns:\n",
    "        raise ValueError(\"Input CSV should contain a 'description' column\")\n",
    "\n",
    "\n",
    "    model = SentenceTransformer(embedding_model_name)\n",
    "\n",
    "    df[\"text\"] = df[\"name\"].fillna(\"\") + \" \" + df[\"description\"].fillna(\"\") + \" \" + df['category'].fillna(\"\") + \" \" + df['type'].fillna(\"\")\n",
    "\n",
    "    text_embeddings = model.encode(df[\"text\"].tolist(), convert_to_numpy=True)\n",
    "\n",
    "    embeddings_df = pd.DataFrame(\n",
    "        text_embeddings,\n",
    "        columns=[f\"emb_{i}\" for i in range(text_embeddings.shape[1])],\n",
    "    )\n",
    "\n",
    "    df = pd.concat([df, embeddings_df], axis=1)\n",
    "    \n",
    "    # create an id column\n",
    "    df['id'] = np.arange(len(df))\n",
    "    \n",
    "    df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv = 'data\\geocoded_addresses.csv'\n",
    "output_csv = 'data\\database_embeddings.csv'\n",
    "model = \"all-MiniLM-L6-v2\"\n",
    "# model = \"embaas/sentence-transformers-e5-large-v2\"\n",
    "# model = \"BAAI/bge-m3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generate_embeddings(input_csv, output_csv, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.read_csv('data\\database_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# are there nan in emb columns?\n",
    "emb_cols = [col for col in embeddings.columns if 'emb' in col]\n",
    "embeddings[emb_cols].isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_matrix(embeddings: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes a similarity matrix from the embeddings.\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings (pd.DataFrame): DataFrame with embeddings.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Similarity matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    emb_cols = [col for col in embeddings.columns if col.startswith(\"emb_\")]\n",
    "    \n",
    "    embeddings = embeddings[emb_cols].values\n",
    "\n",
    "    similarity_matrix = np.inner(embeddings, embeddings)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def top_n_similar(\n",
    "    similarity_matrix: np.ndarray,\n",
    "    place_id: int,\n",
    "    n: int = 5,\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Finds top N similar places for a given place.\n",
    "\n",
    "    Parameters:\n",
    "    - similarity_matrix (np.ndarray): Similarity matrix.\n",
    "    - place_id (int): Place ID to find similar places for.\n",
    "    - n (int): Number of similar places to return.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with similar places.\n",
    "    \"\"\"\n",
    "\n",
    "    similar_places = np.argsort(similarity_matrix[place_id])[::-1][1:n+1]\n",
    "\n",
    "    return similar_places\n",
    "\n",
    "\n",
    "def create_top_n_cols(\n",
    "    embeddings: pd.DataFrame,\n",
    "    similarity_matrix: np.ndarray,\n",
    "    n: int = 5,\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates top N similar places columns for each place.\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings (pd.DataFrame): DataFrame with embeddings.\n",
    "    - similarity_matrix (np.ndarray): Similarity matrix.\n",
    "    - n (int): Number of similar places to return.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with top N similar places columns.\n",
    "    \"\"\"\n",
    "\n",
    "    top_n_cols = []\n",
    "\n",
    "    for i in range(len(embeddings)):\n",
    "        top_n = top_n_similar(similarity_matrix, i, n)\n",
    "        top_n_cols.append(top_n)\n",
    "\n",
    "    top_n_df = pd.DataFrame(top_n_cols, columns=[f\"top_{i+1}\" for i in range(n)])\n",
    "\n",
    "    top_n_df['id'] = np.arange(len(top_n_df))\n",
    "    \n",
    "    embeddings = pd.merge(embeddings, top_n_df, on='id', how='left')\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def compute_similarity_vector(\n",
    "    embedding_query: np.ndarray,\n",
    "    embeddings_base: pd.DataFrame,\n",
    "    ) -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "    Computes a similarity vector for a given place.\n",
    "\n",
    "    Parameters:\n",
    "    - embedding (np.ndarray): Embedding of a query place.\n",
    "    - embeddings (pd.DataFrame): DataFrame with embeddings.\n",
    "    \n",
    "    Returns:\n",
    "    - np.ndarray: Similarity vector.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    emb_cols = [col for col in embeddings_base.columns if col.startswith(\"emb_\")]\n",
    "    embeddings = embeddings_base[emb_cols].values\n",
    "    \n",
    "    similarity_vector = np.inner(embedding_query, embeddings)\n",
    "    \n",
    "    return similarity_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = compute_similarity_matrix(embeddings)\n",
    "top_n_df = create_top_n_cols(embeddings, matrix, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(\n",
    "    search_query: str,\n",
    "    model_name: str = \"all-MiniLM-L6-v2\",\n",
    "    ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates an embedding for a search query.\n",
    "    \n",
    "    Parameters:\n",
    "    - search_query (str): Search query.\n",
    "    - model_name (str): Pretrained SentenceTransformer model name.\n",
    "    \n",
    "    Returns:\n",
    "    - np.ndarray: Embedding for the search query.\n",
    "    \"\"\"\n",
    "    \n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    embedding = model.encode(search_query, convert_to_numpy=True)\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "def top_n_query(\n",
    "    search_query: str,\n",
    "    embeddings: pd.DataFrame,\n",
    "    n: int = 5,\n",
    "    model_name: str = \"all-MiniLM-L6-v2\",\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Finds top N similar places for a given search query.\n",
    "    \n",
    "    Parameters:\n",
    "    - search_query (str): Search query.\n",
    "    - embeddings (pd.DataFrame): DataFrame with embeddings.\n",
    "    - n (int): Number of similar places to return.\n",
    "    - model_name (str): Pretrained SentenceTransformer model name.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with similar places.\n",
    "    \"\"\"\n",
    "    \n",
    "    embedding_query = get_embedding(search_query, model_name)\n",
    "    \n",
    "    similarity_vector = compute_similarity_vector(embedding_query, embeddings)\n",
    "    \n",
    "    similar_places = np.argsort(similarity_vector)[::-1][:n]\n",
    "    \n",
    "    return similar_places\n",
    "\n",
    "def get_places_by_ids(\n",
    "    ids: list,\n",
    "    df: pd.DataFrame,\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Gets places by their IDs.\n",
    "    \n",
    "    Parameters:\n",
    "    - ids (list): List of place IDs.\n",
    "    - embeddings (pd.DataFrame): DataFrame with embeddings.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with places.\n",
    "    \"\"\"\n",
    "    \n",
    "    return df.iloc[ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>type</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Café Noir Bar &amp; Lounge</td>\n",
       "      <td>Dine-in   Takeout   Delivery</td>\n",
       "      <td>eco_cafes</td>\n",
       "      <td>Cafe</td>\n",
       "      <td>-75.567941</td>\n",
       "      <td>6.207344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cafe Fundación.</td>\n",
       "      <td>Dine-in   Takeout</td>\n",
       "      <td>eco_cafes</td>\n",
       "      <td>Cafe</td>\n",
       "      <td>-75.594601</td>\n",
       "      <td>6.243397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>General Cafe Bar</td>\n",
       "      <td>Dine-in   Takeout</td>\n",
       "      <td>eco_cafes</td>\n",
       "      <td>Coffee shop</td>\n",
       "      <td>-75.573069</td>\n",
       "      <td>6.214551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Pergamino | Cafe - Laureles</td>\n",
       "      <td>Dine-in   Takeout   Delivery</td>\n",
       "      <td>eco_cafes</td>\n",
       "      <td>Cafe</td>\n",
       "      <td>-75.596886</td>\n",
       "      <td>6.243245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Urbania Café</td>\n",
       "      <td>Dine-in   Curbside pickup   Delivery</td>\n",
       "      <td>community_gardens</td>\n",
       "      <td>Cafe</td>\n",
       "      <td>-75.567982</td>\n",
       "      <td>6.207446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name                           description  \\\n",
       "20        Café Noir Bar & Lounge          Dine-in   Takeout   Delivery   \n",
       "23               Cafe Fundación.                     Dine-in   Takeout   \n",
       "30              General Cafe Bar                     Dine-in   Takeout   \n",
       "31   Pergamino | Cafe - Laureles          Dine-in   Takeout   Delivery   \n",
       "353                 Urbania Café  Dine-in   Curbside pickup   Delivery   \n",
       "\n",
       "              category         type  Longitude  Latitude  \n",
       "20           eco_cafes         Cafe -75.567941  6.207344  \n",
       "23           eco_cafes         Cafe -75.594601  6.243397  \n",
       "30           eco_cafes  Coffee shop -75.573069  6.214551  \n",
       "31           eco_cafes         Cafe -75.596886  6.243245  \n",
       "353  community_gardens         Cafe -75.567982  6.207446  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str = \"Cafe local\"\n",
    "get_places_by_ids(top_n_query(test_str, embeddings, 5, model_name=model), embeddings)[['name', 'description', 'category', 'type', 'Longitude', 'Latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_strs = [\n",
    "    \"Eco-friendly hotel\",\n",
    "    \"Local Coffee Shop\",\n",
    "    \"Local restaurant\",\n",
    "    \"Park with beautiful views\",\n",
    "    \"Susteinable hostel\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, data_str in enumerate(data_strs, start=1):\n",
    "    result = get_places_by_ids(top_n_query(data_str, embeddings, 5, model_name=model), embeddings)[['name', 'description', 'Longitude', 'Latitude']]\n",
    "    result_dict = {\n",
    "        \"number\": i,\n",
    "        \"prompt\": data_str,\n",
    "        \"data\": result.to_dict(orient='records')\n",
    "    }\n",
    "    results.append(result_dict)\n",
    "\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "top_n_similar() missing 1 required positional argument: 'place_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtop_n_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: top_n_similar() missing 1 required positional argument: 'place_id'"
     ]
    }
   ],
   "source": [
    "top_n_similar(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "undatathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
